---
title: "Autocorrelation experiment: statistical analyses at 37Â°C - frond count"
author: "Debora"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,comment = NA)
```

```{r, include=F, warning=FALSE, message=FALSE}
datin1 <- read.csv("https://raw.githubusercontent.com/Cuddington-Lab/thermal-experiments/main/metafile_autocorrelation_2022-2023.csv",header=TRUE, stringsAsFactors = TRUE,fileEncoding="UTF-8-BOM")

datin2 <- read.csv("https://raw.githubusercontent.com/Cuddington-Lab/thermal-experiments/main/metafile_autocorrelation_2021-2022.csv",header=TRUE, stringsAsFactors = TRUE,fileEncoding="UTF-8-BOM")

datin <- rbind(datin1,datin2)

# Data validation: excluding experiments outside thresholds established in my methods section
# (for standard deviation and autocorrelation of observed temperatures)
datin <- datin[!(datin$Treatment == 0 & (datin$Obs_sd <= 2.1 | datin$Obs_sd >= 2.9))
              &!(datin$Treatment == 0.95 & (datin$Obs_sd <= 2.1 | datin$Obs_sd >= 2.9)),]

datin <- datin[!(datin$Treatment == 0 & (datin$Obs_ac <= -0.2 | datin$Obs_ac >= 0.2))
               &!(datin$Treatment == 0.95 & (datin$Obs_ac <= 0.92 | datin$Obs_ac >= 0.98)),]

# Excluding failed experiments
datin <- datin[!datin$Experiment_Number == 83,]
datin <- datin[!(datin$Experiment_Number == 99 & datin$Incubator ==3),]
datin <- datin[!(datin$Experiment_Number == 99 & datin$Incubator ==4),]

# Selecting average temperature of 37C
datin <- subset(datin, Mean_temperature == 37)

# Create new treatment label (depending on slope of regression for observed temperature series)
table(datin$Treatment, datin$cat_1)
levels(datin$cat_1) = c("N/A","N","P","N/A")
datin$label<-paste0(datin$Treatment, datin$cat_1)
table(datin$label)

# Re-label groups to simplify visualization of results
library(stringr)
datin$label <- str_replace(datin$label, "0N/A", " no autocorrelation")
datin$label <- str_replace(datin$label, "0.95N", "hot-cold")
datin$label <- str_replace(datin$label, "0.95P", "cold-hot")

datin$Species <- str_replace(datin$Species, "Field_LM", "L. minor (native)")
datin$Species <- str_replace(datin$Species, "LP", "L. punctata (invasive)")

datin$Species <- as.factor(datin$Species)
datin$label <- as.factor(datin$label)

# Obtain summed frond counts
datin$Frond_count <- datin$Frond_count_1 + datin$Frond_count_2 + datin$Frond_count_3

datinF <- subset(datin, !Frond_count == 0)
```

### Check dataset (each row corresponds to a replicate)
```{r,echo=FALSE, warning=FALSE, message=FALSE}
knitr::kable(tail(datinF[c(1,5,7,8,32,33)],6),"simple")
```

### Testing several models
```{r,echo=FALSE, warning=FALSE, message=FALSE}
#potential random effects of dishes: This is not being currently done because previous analyses showed that there are no effects of dishes to any of the measurements taken during the experiment

library(lme4)
lm.fit.spF = lm(Frond_count ~ label*Species,  data=datinF)
experimF <- lmer(Frond_count ~ label*Species + (1|Experiment_Number),  data=datinF)
incubF <- lmer(Frond_count ~ label*Species + (1|Incubator),  data=datinF)
inc_expF <- lmer(Frond_count ~ label*Species + (1|Incubator)+(1|Experiment_Number),  data=datinF)
exp.incF <- lmer(Frond_count ~ label*Species + (1|Experiment_Number/Incubator),  data=datinF)

#model assessment
##set up named list
Cand.modsF <- list("no random effects" = lm.fit.spF,
                  "experiment number" = experimF,
                  "incubator" = incubF, 
                  "incubator and experiment number" = inc_expF,
                  "incubator nested in experiment number" = exp.incF)
```


```{r,echo=FALSE, warning=FALSE, message=FALSE}
library(performance)
compareF <- compare_performance(Cand.modsF)
knitr::kable(compareF[,c(1,2,3,4)],"simple")
```

### The best model
```{r echo=TRUE, message=FALSE, warning=FALSE}
experimF <- lmer(Frond_count ~ label*Species + (1|Experiment_Number),  data=datinF)
```

```{r,echo=FALSE, warning=FALSE, message=FALSE}
library(sjPlot)
tab_model(experimF, digits = 3)
```

### Post-hoc pairwise comparisons
```{r,echo=FALSE, warning=FALSE, message=FALSE}
library(emmeans)
f <- emmeans(experimF, list(pairwise ~ label*Species), lmer.df="satterthwaite")
f1 <- as.data.frame(f$`pairwise differences of label, Species`)
f2 <- subset(f1,p.value<=0.05)
knitr::kable(f2,"simple",digits=4)

```

### Barplot for model predictions
```{r,echo=FALSE, warning=FALSE, message=FALSE}
library(interactions)
library(ggplot2)
cat_plot(experimF, pred = label, modx = Species, geom = "bar") + 
  theme_bw(base_size=34) +
  labs(title = "Predicted survival probability") +
  theme(panel.border = element_blank(), 
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(), 
        axis.line = element_line(colour = "black"),
        legend.position = "none") +
  labs(y = "Survival", x = "Survival") +
  scale_fill_manual(values=c("#999999", "#E69F00")) +
  scale_color_manual(values=c("#999999", "#E69F00")) 




### Checking model assumptions
#https://ademos.people.uic.edu/Chapter18.html
#assumptions of linear models and linear mixed models: 
#linearity (in parameters), homoscedasticity (equal variance), 
#normal distribution of residuals, 
#normal distribution of random effects (relevant for linear mixed models only), 
#and independence (no clustering unaccounted for)

#Assumption 1 - Linearity
#The residuals should be approximately normally distributed. The Shapiro-Wilk test 
#can be used to check the normal distribution of residuals. 
#Null hypothesis: data is drawn from a normal distribution.
shapiro.test(resid(experimF))

#As the p-value is non-significant (p > 0.05), we fail to reject the null hypothesis 
# and conclude that data is drawn from a normal distribution

#Assumption 2 - Homogeneity of Variance (homoscedasticity)
#The variance should be similar for all groups. Bartlett's test can be used to check the
#homogeneity of variances. Null hypothesis: samples from populations have equal variances
#https://www.r-bloggers.com/2021/10/analysis-of-covariance-ancova-using-r/
bartlett.test(residuals(experimF) ~ datinF$Treatment)
library(car)
leveneTest(residuals(experimF) ~ datinF$Treatment)
#As the p-value is non-significant (p > 0.05), we fail to reject the null hypothesis 
# and conclude that treatments have equal variances

#Assumption 3: The residuals of the model are normally distributed
require("lattice")
qqmath(experimF, id=0.05)
plot(experimF)
#There is some deviation from from the expected normal line towards the tails, 
#but overall the line looks straight and therefore pretty normal and suggests that the 
#assumption is not violated. See http://data.library.virginia.edu/diagnostic-plots/ 
#and https://www.r-bloggers.com/model-validation-interpreting-residual-plots/ for 
#more information regarding these visual tests
```

